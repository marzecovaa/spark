{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf6231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 15:03:10.018956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Masking, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model, regularizers, layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550d6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data from timeseries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e41545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_lstm(input_shape:tuple, dropout_rate: float = 0.3) -> Model:\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_shape)))\n",
    "    model.add(layers.Masking(mask_value=0.0))\n",
    "    \n",
    "    #two lstm layers to better capture \n",
    "    model.add(LSTM(units=64, activation='tanh', \n",
    "                   return_sequences=True,\n",
    "                   dropout=dropout_rate,           \n",
    "                   recurrent_dropout=dropout_rate))\n",
    "    model.add(LSTM(units=32, activation='tanh',\n",
    "                   dropout=dropout_rate,           \n",
    "                   recurrent_dropout=dropout_rate))\n",
    "    \n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    #dense layer with batch normalization\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    #output layer with 3 classification\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb3d03",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compile() missing required argument 'source' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msparse_categorical_crossentropy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: compile() missing required argument 'source' (pos 1)"
     ]
    }
   ],
   "source": [
    "model_lstm = initialize_model_lstm(input_shape=X_train.shape[1:])\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    metrics=['accuracy', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=50,\n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1, \n",
    "        patience=3, \n",
    "        verbose=1,\n",
    "        min_lr=0\n",
    "    )\n",
    "\n",
    "history = model_lstm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split = 0.2,\n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    callbacks=[es, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
